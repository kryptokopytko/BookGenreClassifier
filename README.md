# ğŸ“š Book Genre Classifier

Automatyczna klasyfikacja gatunkÃ³w literackich na podstawie treÅ›ci ksiÄ…Å¼ek z Project Gutenberg przy uÅ¼yciu metod Machine Learning i NLP.

## ğŸ¯ Opis Projektu

System klasyfikuje ksiÄ…Å¼ki do 8 gatunkÃ³w literackich:

- Adventure/Action
- Biography
- Mystery/Crime
- Science Fiction
- Historical Fiction
- Thriller/Horror
- Fantasy
- Romance

**GÅ‚Ã³wne cechy:**

- âœ… 10 rÃ³Å¼nych modeli ML (od prostych baseline do ensemble)
- âœ… PodziaÅ‚ danych author-based (zapobiega data leakage)
- âœ… Ekstrakcja cech TF-IDF i statystycznych
- âœ… Kompleksowa ewaluacja z wizualizacjami
- âœ… ModuÅ‚owa architektura kodu

## ğŸ“ Struktura

```
book-genre-classifier/
â”œâ”€â”€ src/                    # Kod ÅºrÃ³dÅ‚owy (data, features, models, evaluation)
â”œâ”€â”€ scripts/                # Skrypty treningowe
â”œâ”€â”€ data/                   # raw/, processed/, metadata.csv
â”œâ”€â”€ models_saved/           # Wytrenowane modele (.pkl)
â””â”€â”€ results/                # Wyniki i metryki
```

## ğŸ“Š Dataset

**Å¹rÃ³dÅ‚o:** Project Gutenberg (darmowe e-booki)

**Aktualny rozmiar:**

- **Total:** 3,703 ksiÄ…Å¼ki
- Train: 2,202 (59.5%)
- Validation: 461 (12.4%)
- Test: 1,040 (28.1%)

**RozkÅ‚ad gatunkÃ³w (prawie zbalansowany!):**

```
Fantasy:            502 ksiÄ…Å¼ki âœ…
Historical Fiction: 499 ksiÄ…Å¼ek âœ…
Thriller/Horror:    498 ksiÄ…Å¼ek âœ…
Science Fiction:    498 ksiÄ…Å¼ek âœ…
Mystery/Crime:      495 ksiÄ…Å¼ek âœ…
Romance:            495 ksiÄ…Å¼ek âœ…
Adventure/Action:   489 ksiÄ…Å¼ek âœ…
Biography:          443 ksiÄ…Å¼ki âœ…
```

**Stan:** Dataset znacznie poprawiony! Wszystkie gatunki majÄ… ~450-500 ksiÄ…Å¼ek.

## ğŸ”§ Setup

```bash
pip install numpy pandas scikit-learn matplotlib seaborn tqdm nltk requests beautifulsoup4
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"
```

## ğŸš€ Quick Start

```bash
# 1. Generate metadata from existing books
python3 scripts/generate_metadata_from_existing.py

# 2. Preprocess and split data
python3 scripts/download_books.py --skip_download

# 3. Extract features (fast - without POS/keywords)
python3 scripts/extract_features.py --skip_pos --skip_keywords

# 4. Train models
python3 scripts/train_simple.py

# 5. Test and optimize
python3 scripts/test_and_optimize.py
```

**Note**: See [SCRIPTS_STATUS.md](SCRIPTS_STATUS.md) for complete script documentation and troubleshooting.

## ğŸ“ˆ Wyniki

### Wytrenowane Modele (Dataset: 3,703 ksiÄ…Å¼ki)

| Model                   | Val Acc | Test Acc  | Status                         |
| ----------------------- | ------- | --------- | ------------------------------ |
| **Linear SVM (C=10)**   | 53.4%   | **53.0%** | âœ… Najlepszy (zoptymalizowany) |
| **Linear SVM (C=1)**    | 50.1%   | 53.6%     | âœ… Dobry                       |
| **Logistic Regression** | 46.2%   | 47.5%     | âœ… Stabilny                    |
| **Random Forest**       | 34.5%   | 36.2%     | âš ï¸ Overfitting                 |
| **Naive Bayes**         | 32.1%   | 27.0%     | âš ï¸ SÅ‚aby                       |

### Najlepszy Model: Optimized Linear SVM (C=10.0)

**Test Accuracy: 53.0%**

**Per-Genre Performance:**

- ğŸ¥‡ **Biography**: 84% F1 (92% precision!)
- ğŸ¥ˆ **Mystery/Crime**: 65% F1
- ğŸ¥‰ **Romance**: 56% F1
- âš ï¸ **Fantasy**: 21% F1 (najtrudniejszy)
- âš ï¸ **Thriller/Horror**: 29% F1

### Analiza Modeli

âœ… **Linear SVM**: Najlepszy trade-off miÄ™dzy accuracy a generalizacjÄ…

âœ… **Logistic Regression**: Najbardziej stabilny (niewielki gap train-test)

âš ï¸ **Random Forest**: Silny overfitting mimo max_depth=15

- Train: 86.1% â†’ Test: 36.3% (gap: 49.8 punktÃ³w procentowych!)
- Potrzebuje regularyzacji lub wiÄ™cej danych

âš ï¸ **Naive Bayes**: Zbyt prosty dla tego problemu (8 klas, podobne gatunki)

### Interpretacja WynikÃ³w

**Dlaczego ~50% accuracy?**

1. **8 klas**: Random baseline to 12.5%, wiÄ™c 53.6% to solidny wynik
2. **Podobne gatunki**: Science Fiction vs Fantasy, Romance vs Historical Fiction - trudne do rozrÃ³Å¼nienia
3. **Brak keyword features**: Baseline model (keywords) nie byÅ‚ trenowany
4. **Brak POS features**: PominÄ™liÅ›my wolnÄ… analizÄ™ POS

**PorÃ³wnanie z literaturÄ…:**

- Multi-class text classification (8 klas): 40-70% accuracy jest typowe
- BERT/transformers osiÄ…gajÄ… ~70-80%, ale wymagajÄ… GPU i dÅ‚ugiego trenowania

## ğŸ¯ Kluczowe Cechy

- **Author-based split**: Å»aden autor w train i test jednoczeÅ›nie (zapobiega data leakage)
- **TF-IDF features**: Unigrams + bigrams, max 5000 features
- **Statistical features**: Sentence length, vocabulary richness, etc.

### ğŸ¯ Potencjalne Dalsze Usprawnienia

**Quick wins (+5-10%):**

1. Keyword features + baseline model
2. POS analysis (pomijaliÅ›my ze wzglÄ™du na czas)
3. Ensemble voting z top 3 modeli

**Medium effort (+10-15%):** 4. Word embeddings (Word2Vec/GloVe) 5. Feature engineering (dialog ratio, chapter structure) 6. Cross-validation

**Advanced (+15-25%):** 7. Fine-tune BERT/RoBERTa 8. Hierarchical classification 9. Dataset expansion (5000+ books)

---

**Status:** âœ… Fully Functional | âœ¨ Optimized
**Wersja:** 1.2.0
**Ostatnia aktualizacja:** 2026-02-05

**Final Results:**

- **Dataset**: 3,703 ksiÄ…Å¼ki (zbalansowany: ~450-500 per gatunek)
- **Best Model**: Optimized Linear SVM (C=10.0)
- **Test Accuracy**: 53.0% (vs 12.5% random baseline)
- **Best Genre**: Biography (84% F1-score)
- **Models**: 5 wytrenowanych modeli w `models_saved/`
- **Optimization**: Hyperparameter tuning wykonany
- **Code**: Wszystkie moduÅ‚y naprawione i testowalne
